Building the SafeBoda Rwanda API was a chance to mix the latest Django tricks with real-world quirks, like spotty internet and pricey mobile data. The trickiest part was creating location services that load fast but won’t break the bank when called over and over from bikes weaving through Kigali traffic. One or two intentional design moves made a way bigger difference than I expected: true async I/O, cache keys that pay attention to how folks actually behave, and small, sensible payloads. The impact was huge.  
  
At first, I wrestled with async since Django views like to look plain synchronous. It clicked when I wrapped external HTTP calls in `aiohttp` and made heavy math (like haversine distance) super lightweight. That kept the event loop breathing. Another lesson was to keep async calls at the edges instead of the whole view. I added async only when I pause for the network. The code stayed readable, and I still got the fast I wanted.  
  
Caching got interesting since it’s not just about speed; it’s about breaking the cache at the right time too. Kigali traffic is lively, but it settles after a beat, so I picked a five-minute TTL for nearby drivers. I name-cache keys like `nearby:{lat}:{lng}:{radius}` and `rgeo:{lat}:{lng}` and jotted down what clears what: when a driver updates, I only kick out the keys in their neighborhood. I added simple hit and miss counters to check how it’s working. That dashboard helped me tweak those TTLs with confidence.

For pagination, keep mobile data in mind. A small default (`limit=10`), predictable shapes, plus server-side filters mean the app pulls in just the right amount. Sticking with one approach matters: every list endpoint uses the same `page`/`limit`/`search` fields, so our app coders can drop list bits anywhere. When the info needs to be almost live, like when the app shows nearby drivers, cursor pagination avoids showing the same driver twice if you flip to the next page.

Building for Rwanda meant thinking beyond the code. Networks can drop out, and every byte is valuable, so idempotent endpoints, cache-friendly headers, and skinny JSON are the rule, not the bonus. Error messages are extra-clear, because the network can’t always tell if the phone or the server is the troublemaker. I also kept offline needs in mind, like saving location pings to send later, by letting endpoints handle batch requests so they can catch up without losing data.

If tomorrow came with a sprint for adding more code, I’d finalize Redis for caching, tie the stats to Prometheus and Grafana, toss in circuit breakers and retries for the third-party map calls, and start a background job for fancier driver guessing that uses spatial indexes from PostGIS. On top of that, I’d add property-based tests for wild map edges and bump rate limiting to better fit the quirks of mobile connections.

Working on this project really helped me nail async in Python web apps, design caching right, and figure out how to do pagination so it works with African internet conditions. The big lesson was to make sure the happy path is speedy, use async and caching to keep things zip, and to make the failure path friendly by showing clear errors, trying a couple of times, and sending only tiny payloads. When you do both, the app feels reliable, even when the network is having a rough day.

